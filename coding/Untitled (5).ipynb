{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            JOB_TITLE         JOB_CATERGORY  \\\n",
      "0                    Application Consultant: DevOps              Consultant   \n",
      "1                    Practitioner -Customer Service                 Finance   \n",
      "2   Application Developer: Enterprise Asset Manage...  Technical Specialist   \n",
      "3   Application Developer: Enterprise Asset Manage...  Technical Specialist   \n",
      "4   Application Developer: Enterprise Asset Manage...  Technical Specialist   \n",
      "5   Application Developer: SAP Enterprise Integrat...  Technical Specialist   \n",
      "6                Application Consultant: ServiceNow              Consultant   \n",
      "7       Application Developer: Experience Front End    Technical Specialist   \n",
      "8                    Package Consultant: Salesforce              Consultant   \n",
      "9                    Package Consultant: Salesforce              Consultant   \n",
      "10                  Data Engineer: Data Integration    Technical Specialist   \n",
      "11                                           Intern                   Other   \n",
      "12                          Data Engineer: Big Data    Technical Specialist   \n",
      "13                          Data Engineer: Big Data    Technical Specialist   \n",
      "14                          Data Engineer: Big Data    Technical Specialist   \n",
      "15                          Data Engineer: Big Data    Technical Specialist   \n",
      "16                          Data Engineer: Big Data    Technical Specialist   \n",
      "17                          Data Engineer: Big Data    Technical Specialist   \n",
      "18                          Data Engineer: Big Data    Technical Specialist   \n",
      "19                          Data Engineer: Big Data    Technical Specialist   \n",
      "20                          Data Engineer: Big Data    Technical Specialist   \n",
      "21                          Data Engineer: Big Data    Technical Specialist   \n",
      "22                          Data Engineer: Big Data    Technical Specialist   \n",
      "23                          Data Engineer: Big Data    Technical Specialist   \n",
      "24                          Data Engineer: Big Data    Technical Specialist   \n",
      "25                          Data Engineer: Big Data    Technical Specialist   \n",
      "26                          Data Engineer: Big Data    Technical Specialist   \n",
      "27                          Data Engineer: Big Data    Technical Specialist   \n",
      "28                          Data Engineer: Big Data    Technical Specialist   \n",
      "29                          Data Engineer: Big Data    Technical Specialist   \n",
      "\n",
      "         LOCATION            STATE    JOB_ID  \n",
      "0       KARNATAKA        Bangalore  334519BR  \n",
      "1         HARYANA          Gurgaon  333200BR  \n",
      "2      TAMIL NADU          Chennai  339744BR  \n",
      "3      TAMIL NADU          Chennai  339743BR  \n",
      "4      TAMIL NADU          Chennai  339742BR  \n",
      "5   UTTAR PRADESH            Noida  339081BR  \n",
      "6     MAHARASHTRA             Pune  339736BR  \n",
      "7       TELANGANA        Hyderabad  339786BR  \n",
      "8       KARNATAKA        Bangalore  335222BR  \n",
      "9       KARNATAKA        Bangalore  335632BR  \n",
      "10      KARNATAKA        Bangalore  336362BR  \n",
      "11       MULTIPLE  MULTIPLE CITIES  337033BR  \n",
      "12    MAHARASHTRA             Pune  338175BR  \n",
      "13    MAHARASHTRA             Pune  338176BR  \n",
      "14    MAHARASHTRA             Pune  338177BR  \n",
      "15    MAHARASHTRA             Pune  338178BR  \n",
      "16    MAHARASHTRA             Pune  338180BR  \n",
      "17      KARNATAKA        Bangalore  338296BR  \n",
      "18      KARNATAKA        Bangalore  338298BR  \n",
      "19      KARNATAKA        Bangalore  338299BR  \n",
      "20      KARNATAKA        Bangalore  338304BR  \n",
      "21      KARNATAKA        Bangalore  338307BR  \n",
      "22      KARNATAKA        Bangalore  338308BR  \n",
      "23      KARNATAKA        Bangalore  338310BR  \n",
      "24      KARNATAKA        Bangalore  338319BR  \n",
      "25      KARNATAKA        Bangalore  338323BR  \n",
      "26      KARNATAKA        Bangalore  338326BR  \n",
      "27      KARNATAKA        Bangalore  338328BR  \n",
      "28      KARNATAKA        Bangalore  338331BR  \n",
      "29      KARNATAKA        Bangalore  338332BR  \n"
     ]
    }
   ],
   "source": [
    "#IBM COMPANY WEB SCRAPPING\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "col = ['JOB_TITLE', 'JOB_CATERGORY', 'LOCATION', 'STATE']\n",
    "sample_df = pd.DataFrame(columns = col) #to create the empty dataframe\n",
    "page = requests.get(\"https://careers.ibm.com/ListJobs/All/Search/Country/IN//?lang=en\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "for  t in  soup.find_all(name='table', attrs={'class':'JobListTable'}): \n",
    "    job_post=[]\n",
    "    g=t.find_all(name='td', attrs={'class':'coloriginaljobtitle'})\n",
    "    for i in range(len(g)):\n",
    "        s=str(g[i]).replace(\"</a>\",\" \")\n",
    "        s1=s.replace(\"</td>\",\" \")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    m=(t.find_all(name='td',attrs={'class':'colshorttextfield1'}))\n",
    "    if len(m) > 0:\n",
    "            for b in m:\n",
    "                    job_post.append(b.text.strip())\n",
    "    sample_df['JOB_CATERGORY']=job_post\n",
    "    job_post=[]\n",
    "    n=(t.find_all(name='td',attrs={'class':'colshorttextfield19'}))\n",
    "    if len(n) > 0:\n",
    "            for b in n:\n",
    "                    job_post.append(b.text.strip())\n",
    "    sample_df['LOCATION']=job_post\n",
    "    job_post=[]\n",
    "    o=(t.find_all(name='td',attrs={'class':'colcity'}))\n",
    "    if len(o) > 0:\n",
    "            for b in o:\n",
    "                    job_post.append(b.text.strip())\n",
    "    sample_df['STATE']=job_post\n",
    "    job_post=[]\n",
    "    p=(t.find_all(name='td',attrs={'class':'coldisplayjobid'}))\n",
    "    if len(p) > 0:\n",
    "            for b in p:\n",
    "                    job_post.append(b.text.strip())\n",
    "    sample_df['JOB_ID']=job_post\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      JOB_TITLE REQUISTION ID  POSTED DATE\n",
      "0            Java Microservices        132842  Oct 7, 2020\n",
      "1  Sr. C++ Dicom Linux Engineer        133641  Oct 7, 2020\n",
      "2     Machine Learning Engineer        125684  Oct 6, 2020\n",
      "3     Technical Project Manager        118902  Oct 6, 2020\n",
      "4     Machine Learning Engineer        125701  Oct 6, 2020\n",
      "                    JOB_TITLE REQUISTION ID  POSTED DATE\n",
      "0     Andorid Audio Developer         87991  Oct 6, 2020\n",
      "1  Android Graphics Developer         87981  Oct 6, 2020\n",
      "2             RDK B Developer        119341  Oct 6, 2020\n",
      "3      Consultant - Thingworx         93965  Oct 6, 2020\n",
      "4                        Lead        111303  Oct 6, 2020\n",
      "                           JOB_TITLE REQUISTION ID  POSTED DATE\n",
      "0                    RDK B Developer        119342  Oct 6, 2020\n",
      "1        ESP PSW Build plan Engineer        120703  Oct 6, 2020\n",
      "2                OTT Senior Engineer        132146  Oct 6, 2020\n",
      "3  Sr.Hardware Board Design Engineer        120863  Oct 6, 2020\n",
      "4          Manufacturing Digital SME        117429  Oct 6, 2020\n",
      "                                JOB_TITLE REQUISTION ID   POSTED DATE\n",
      "0                                Engineer        112344   Oct 6, 2020\n",
      "1  Groovy/Java Automation Engg - LTE/3GPP         88787   Oct 5, 2020\n",
      "2             WIFI  Test Engineer(Tester)         88663   Oct 5, 2020\n",
      "3                       ReactJS Developer        132821   Oct 1, 2020\n",
      "4                         Senior Engineer        121222  Sep 30, 2020\n",
      "                             JOB_TITLE REQUISTION ID   POSTED DATE\n",
      "0                 RTM Python Developer        124363  Sep 28, 2020\n",
      "1             Python Developer Support        123682  Sep 28, 2020\n",
      "2  Senior Clinical Documetation Expert        128125  Sep 28, 2020\n",
      "3              Azure .Net C# Developer        130903  Sep 28, 2020\n",
      "4                         UI Developer        124941  Sep 28, 2020\n"
     ]
    }
   ],
   "source": [
    "#L&T infotech web scrapping\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "col = ['JOB_TITLE','REQUISTION ID','POSTED DATE']\n",
    "sample_df = pd.DataFrame(columns = col)\n",
    "page = requests.get(\"https://jobs.ltts.com/go/INDIA/4590610/?q=&sortColumn=referencedate&sortDirection=desc\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "for t in soup.find_all(name='table',attrs={'id':'searchresults'}):\n",
    "    k=t.find_all(name='span',attrs={'class':'jobTitle hidden-phone'})\n",
    "    job_post=[]\n",
    "    for i in range(len(k)):\n",
    "        s=str(k[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    l=t.find_all(name='span',attrs={'class':'jobFacility'})\n",
    "    for i in range(1,len(l)):\n",
    "        s=str(l[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    res = [] \n",
    "    [res.append(x) for x in job_post if x not in res] \n",
    "    sample_df['REQUISTION ID']=res\n",
    "    n=t.find_all(name='span',attrs={\"class\":'jobDate'})\n",
    "    job_post=[]\n",
    "    for i in range(1,len(n),2):\n",
    "        s=str(n[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:s1.find('\\t')] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "print(sample_df)\n",
    "page1 = requests.get(\"https://jobs.ltts.com/go/INDIA/4590610/5/?q=&sortColumn=referencedate&sortDirection=desc\")\n",
    "soup1 = BeautifulSoup(page1.text, 'html.parser')\n",
    "for t in soup1.find_all(name='table',attrs={'id':'searchresults'}):\n",
    "    k=t.find_all(name='span',attrs={'class':'jobTitle hidden-phone'})\n",
    "    job_post=[]\n",
    "    for i in range(len(k)):\n",
    "        s=str(k[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    l=t.find_all(name='span',attrs={'class':'jobFacility'})\n",
    "    for i in range(1,len(l)):\n",
    "        s=str(l[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    res = [] \n",
    "    [res.append(x) for x in job_post if x not in res] \n",
    "    sample_df['REQUISTION ID']=res\n",
    "    n=t.find_all(name='span',attrs={\"class\":'jobDate'})\n",
    "    job_post=[]\n",
    "    for i in range(1,len(n),2):\n",
    "        s=str(n[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:s1.find('\\t')] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "print(sample_df)\n",
    "page2 = requests.get(\"https://jobs.ltts.com/go/INDIA/4590610/10/?q=&sortColumn=referencedate&sortDirection=desc\")\n",
    "soup2 = BeautifulSoup(page2.text, 'html.parser')\n",
    "for t in soup2.find_all(name='table',attrs={'id':'searchresults'}):\n",
    "    k=t.find_all(name='span',attrs={'class':'jobTitle hidden-phone'})\n",
    "    job_post=[]\n",
    "    for i in range(len(k)):\n",
    "        s=str(k[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    l=t.find_all(name='span',attrs={'class':'jobFacility'})\n",
    "    for i in range(1,len(l)):\n",
    "        s=str(l[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    res = [] \n",
    "    [res.append(x) for x in job_post if x not in res] \n",
    "    sample_df['REQUISTION ID']=res\n",
    "    n=t.find_all(name='span',attrs={\"class\":'jobDate'})\n",
    "    job_post=[]\n",
    "    for i in range(1,len(n),2):\n",
    "        s=str(n[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:s1.find('\\t')] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "print(sample_df)\n",
    "page3 = requests.get(\"https://jobs.ltts.com/go/INDIA/4590610/15/?q=&sortColumn=referencedate&sortDirection=desc\")\n",
    "soup3 = BeautifulSoup(page3.text, 'html.parser')\n",
    "for t in soup3.find_all(name='table',attrs={'id':'searchresults'}):\n",
    "    k=t.find_all(name='span',attrs={'class':'jobTitle hidden-phone'})\n",
    "    job_post=[]\n",
    "    for i in range(len(k)):\n",
    "        s=str(k[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    l=t.find_all(name='span',attrs={'class':'jobFacility'})\n",
    "    for i in range(1,len(l)):\n",
    "        s=str(l[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    res = [] \n",
    "    [res.append(x) for x in job_post if x not in res] \n",
    "    sample_df['REQUISTION ID']=res\n",
    "    n=t.find_all(name='span',attrs={\"class\":'jobDate'})\n",
    "    job_post=[]\n",
    "    for i in range(1,len(n),2):\n",
    "        s=str(n[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:s1.find('\\t')] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "print(sample_df)\n",
    "page4 = requests.get(\"https://jobs.ltts.com/go/INDIA/4590610/20/?q=&sortColumn=referencedate&sortDirection=desc\")\n",
    "soup4 = BeautifulSoup(page4.text, 'html.parser')\n",
    "for t in soup4.find_all(name='table',attrs={'id':'searchresults'}):\n",
    "    k=t.find_all(name='span',attrs={'class':'jobTitle hidden-phone'})\n",
    "    job_post=[]\n",
    "    for i in range(len(k)):\n",
    "        s=str(k[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['JOB_TITLE']=job_post\n",
    "    job_post=[]\n",
    "    l=t.find_all(name='span',attrs={'class':'jobFacility'})\n",
    "    for i in range(1,len(l)):\n",
    "        s=str(l[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    res = [] \n",
    "    [res.append(x) for x in job_post if x not in res] \n",
    "    sample_df['REQUISTION ID']=res\n",
    "    n=t.find_all(name='span',attrs={\"class\":'jobDate'})\n",
    "    job_post=[]\n",
    "    for i in range(1,len(n),2):\n",
    "        s=str(n[i]).replace(\"</a>\",\"\")\n",
    "        s1=s.replace(\"</span>\",\"\")\n",
    "        s2=s1[s1.rfind(\">\")+1:s1.find('\\t')] \n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "print(sample_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               DESIGNATION    POSTED DATE LOCATION EXPERIENCE\n",
      "0                          Technical Lead   Sep 23, 2020   Chennai   5-8Years\n",
      "1                           Lead Engineer   Sep 23, 2020   Chennai   5-7Years\n",
      "2         Customer Service Representative   Sep 22, 2020     Noida    Fresher\n",
      "3  Senior Customer Service Representative   Sep 22, 2020     Noida   1-3Years\n",
      "4                       Process Associate   Sep 22, 2020     Noida    Fresher\n",
      "5                          Technical Lead   Sep 21, 2020     Noida   5-8Years\n"
     ]
    }
   ],
   "source": [
    "#HCL web scrapping \n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "col = ['DESIGNATION','POSTED DATE', 'LOCATION','EXPERIENCE']\n",
    "sample_df = pd.DataFrame(columns = col)\n",
    "page = requests.get(\"https://www.hcltech.com/careers/Careers-in-india\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "for t in soup.find_all(name='table', attrs={'class':'views-table cols-4 table table-hover table-striped'}):\n",
    "    l=t.find_all(name='td', attrs={'class':'views-field views-field-field-kenexa-jobs-designation'})\n",
    "    job_post=[]\n",
    "    for i in range(len(l)):\n",
    "        s=str(l[i]).replace('</a>','')\n",
    "        s1=s.replace('</td>','')\n",
    "        s2=s1[s1.rfind(\">\")+1:]\n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['DESIGNATION']=job_post\n",
    "    job_post=[]\n",
    "    m=t.find_all(name='td',attrs={'class':'views-field views-field-field-kenxa-jobs-updated-date'})\n",
    "    for i in range(len(m)):\n",
    "        s=str(m[i]).replace('</span>','')\n",
    "        s1=s.replace('</td>','')\n",
    "        s2=s1[s1.rfind(\">\")+1:]\n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        job_post.append(s3)\n",
    "    sample_df['POSTED DATE']=job_post\n",
    "    job_post=[]\n",
    "    n=t.find_all(name='td',attrs={'class':'views-field views-field-field-kenexa-jobs-location'})\n",
    "    for i in range(len(n)):\n",
    "        s1=str(n[i]).replace('</td>','')\n",
    "        s2=s1[s1.rfind(\">\")+1:]\n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        s4=s3.replace(\" \",'')\n",
    "        job_post.append(s4)\n",
    "    sample_df['LOCATION']=job_post   \n",
    "    job_post=[]\n",
    "    b=t.find_all(name='td',attrs={'class':'views-field views-field-field-kenexa-experience-range'})\n",
    "    for i in range(len(b)):\n",
    "        s1=str(b[i]).replace('</td>','')\n",
    "        s2=s1[s1.rfind(\">\")+1:]\n",
    "        s3=s2.replace(\"\\n\",\"\")\n",
    "        s4=s3.replace(\" \",'')\n",
    "        job_post.append(s4)\n",
    "    sample_df['EXPERIENCE']=job_post    \n",
    "print(sample_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
